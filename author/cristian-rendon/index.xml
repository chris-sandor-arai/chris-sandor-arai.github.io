<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Cristian Rendon | Team ARAI</title><link>https://ar-ai.org/author/cristian-rendon/</link><atom:link href="https://ar-ai.org/author/cristian-rendon/index.xml" rel="self" type="application/rss+xml"/><description>Cristian Rendon</description><generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Fri, 13 Feb 2026 00:00:00 +0000</lastBuildDate><image><url>https://ar-ai.org/author/cristian-rendon/avatar_hu298a8a0703fc2412aa0e538c19cde8f7_2603519_270x270_fill_q75_lanczos_center.jpg</url><title>Cristian Rendon</title><link>https://ar-ai.org/author/cristian-rendon/</link></image><item><title>Cristian's PhD Defense</title><link>https://ar-ai.org/post/26-13-02-cristian-defense/</link><pubDate>Fri, 13 Feb 2026 00:00:00 +0000</pubDate><guid>https://ar-ai.org/post/26-13-02-cristian-defense/</guid><description>&lt;p>I am pleased to invite you to the defense of my PhD thesis titled:&lt;/p>
&lt;p>&lt;strong>Enhancing Human Performance Through Augmented Vision&lt;/strong>&lt;/p>
&lt;p>supervised by: Professeur Christian SANDOR, Maître de conférences Richard LEGRAS et Maître de conférences Marie-Anne BURCKLEN.&lt;/p>
&lt;p>The defense will be held in English and will take place on Monday, February 16th, 2026 at 14:00.&lt;/p>
&lt;h2 id="location">Location:&lt;/h2>
&lt;p>Room: Salle Conférences - Campus Universitaire bât.507 - Rue du Belvédère 91405 - Orsay.&lt;/p>
&lt;p>Online: &lt;a href="https://bbb.lisn.upsaclay.fr/rooms/n3k-chl-cpk-ghs/join" target="_blank" rel="noopener">https://bbb.lisn.upsaclay.fr/rooms/n3k-chl-cpk-ghs/join&lt;/a>&lt;/p>
&lt;h2 id="jury">Jury:&lt;/h2>
&lt;p>M. Vincent NOURRIT , Professeur , IMT Atlantique, Rapporteur
Mme Stefanie ZOLLMANN, Associate Professor, Aarhus University, Rapporteure
M. Laurent VABRE, Docteur , Imagine Eyes, Examinateur
M. Gabriele FACCIOLO, Professeur, ENS Paris-Saclay, Examinateur&lt;/p>
&lt;p>Keywords: Augmented Vision, Human-Computer Interaction, Human Visual System, Freeform Lenses, Spatial Light Modulator, Computational Optics&lt;/p>
&lt;h2 id="abstract">Abstract:&lt;/h2>
&lt;p>Augmented Vision (AV) is an emerging field that aims to enhance human sight by directly modulating a user&amp;rsquo;s view of the real world. Unlike traditional visual aids such as spectacles or contact lenses that provide static correction, AV systems offer dynamic, real-time modulation of the real world. This capability to actively change the user&amp;rsquo;s view opens up new possibilities for both correcting and augmenting human vision. One of the three most common applications for AV is vision correction. This is particularly relevant for presbyopia, an age-related condition affecting 1.8 billion people worldwide. Conventional solutions, such as progressive glasses or multifocal contact lenses, offer a static compromise with fixed focal zones or averaged focus, respectively. In contrast, AV systems use their inherently dynamic behaviour to address these limitations. For instance, some systems use automatic single focus approaches using focus-tunable lenses to focus at specific depths. However, this approach is limited to applying one optical power across the entire field of view at a time. The alternatives are multifocal systems, which provide granular, spatial control over focus. However, while the concept has been demonstrated, there is a lack of objective evaluation of the imaging quality of such systems.&lt;/p>
&lt;p>This thesis addresses two primary objectives. The first is to establish a conceptual framework for Augmented Vision by stating a formal definition and a new taxonomy that categorises existing systems by their light modulation method. The second is to address a gap identified by this framework: the lack of multifocal augmented vision systems and the evaluation of their imaging performance. To tackle the challenges of providing multifocal vision, this thesis proposes an optical architecture that combines a phase-only Spatial Light Modulator (SLM) with a Lohmann lens, allowing spatial control of the optical power over the Field Of View (FOV), providing see-through, real-world modulation. We validate the prototype by measuring the Modulation Transfer Function (MTF) for global and multifocal correction, placing objects at various depths and setting the system&amp;rsquo;s focus at them. We use a camera with its focus set to infinity to simulate a presbyopic eye during the measurements. The results confirm that the system can bring objects from multiple depths into focus, demonstrating a higher MTF for each focused plane when the system is active compared to the inactive condition.&lt;/p>
&lt;p>This thesis provides two primary contributions: (1) a formal conceptual framework for AV systems that identifies the research gap, and (2) a prototype of an optical platform for multifocal vision and its evaluation. This platform serves as foundational technology for exploring a new class of interfaces based on spatially-variant optical power to enhance visual perception and address widespread visual impairments.&lt;/p></description></item></channel></rss>