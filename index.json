[{"authors":null,"categories":null,"content":"I am currently pursuing a PhD in Artificial Intelligence with a focus on advancing high-quality, real-time image generation. My research builds on a strong foundation in computer vision, having previously contributed to various projects at Picsart AI Research (PAIR). These projects include image outpainting/inpainting, texture generation, style transfer, text-to-image generation, and text-to-multiview generation, all aimed at pushing the boundaries of AI-driven visual creativity.\n","date":1756771200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1756771200,"objectID":"7ba7d4e5b5393de15795fd1e735af7b7","permalink":"https://ar-ai.org/author/hovhannes-margaryan/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/hovhannes-margaryan/","section":"authors","summary":"I am currently pursuing a PhD in Artificial Intelligence with a focus on advancing high-quality, real-time image generation. My research builds on a strong foundation in computer vision, having previously contributed to various projects at Picsart AI Research (PAIR).","tags":null,"title":"Hovhannes Margaryan","type":"authors"},{"authors":null,"categories":null,"content":"Exploring the research world in the spirit of Alexander von Humboldt. Publishing on Augmented Reality since 2000. Born and raised in Munich (Germany). Abroad since graduation in 2005. Read more on my personal homepage\n","date":1752105600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1752105600,"objectID":"a96325e743d044df6670ca4f8a7b3395","permalink":"https://ar-ai.org/author/christian-sandor/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/christian-sandor/","section":"authors","summary":"Exploring the research world in the spirit of Alexander von Humboldt. Publishing on Augmented Reality since 2000. Born and raised in Munich (Germany). Abroad since graduation in 2005. Read more on my personal homepage","tags":null,"title":"Christian Sandor","type":"authors"},{"authors":null,"categories":null,"content":"Pursuing a PhD in Augmented Vision focusing on enhancing human visual capabilities through computational optics. Passionate about researching to contribute to people’s lives.\n","date":1752105600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1752105600,"objectID":"25efc737ff2b3e8a140c1a04499f0b33","permalink":"https://ar-ai.org/author/cristian-rendon/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/cristian-rendon/","section":"authors","summary":"Pursuing a PhD in Augmented Vision focusing on enhancing human visual capabilities through computational optics. Passionate about researching to contribute to people’s lives.","tags":null,"title":"Cristian Rendon","type":"authors"},{"authors":null,"categories":null,"content":"I am a Master’s student interested in immersive technologies, human-computer interaction, multisensory perception and communication. In the lab, my project explores various 3D visualization techniques for surgical applications. Outside of academia, I enjoy knitting and hiking.\n","date":1739836800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1739836800,"objectID":"69060e1904e852d16dc1f7bda669a8a3","permalink":"https://ar-ai.org/author/zofia-samsel/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/zofia-samsel/","section":"authors","summary":"I am a Master’s student interested in immersive technologies, human-computer interaction, multisensory perception and communication. In the lab, my project explores various 3D visualization techniques for surgical applications. Outside of academia, I enjoy knitting and hiking.","tags":null,"title":"Zofia Samsel","type":"authors"},{"authors":null,"categories":null,"content":"Born and raised in Kanagawa (Japan). Currently a master’s student in Japan. My hobbies: Cheerleading and Travel.\n","date":17388e5,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":17388e5,"objectID":"dc85ebaf48112f5aa4d987dec9d22be2","permalink":"https://ar-ai.org/author/mizuki-akiyama/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/mizuki-akiyama/","section":"authors","summary":"Born and raised in Kanagawa (Japan). Currently a master’s student in Japan. My hobbies: Cheerleading and Travel.","tags":null,"title":"Mizuki Akiyama","type":"authors"},{"authors":null,"categories":null,"content":"Research Engineer and member of the National Artificial Intelligence Research Program Network (PNRIA/CNRS). I work closely with research teams, supporting their AI-related projects.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"34272b7b8685374beddb076a5eb9e2d8","permalink":"https://ar-ai.org/author/cyrille-leroux/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/cyrille-leroux/","section":"authors","summary":"Research Engineer and member of the National Artificial Intelligence Research Program Network (PNRIA/CNRS). I work closely with research teams, supporting their AI-related projects.","tags":null,"title":"Cyrille Leroux","type":"authors"},{"authors":null,"categories":null,"content":"PhD student in Augmented Reality. With the interest of enhancing human performance using spatial intelligent systems to support remote communication and collaboration for creatives and designers.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"7f8de235c54bd43f288e5d6c2085fa90","permalink":"https://ar-ai.org/author/david-maruscsak/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/david-maruscsak/","section":"authors","summary":"PhD student in Augmented Reality. With the interest of enhancing human performance using spatial intelligent systems to support remote communication and collaboration for creatives and designers.","tags":null,"title":"Dávid Maruscsák","type":"authors"},{"authors":null,"categories":null,"content":"I am a PhD student exploring the potential use of cutting-edge technologies such as Artificial Intelligence (AI) and Virtual Reality (VR) in educational contexts. My research primarily focuses on integrating these technologies into training environments to create new and innovative ways to develop soft skills that are crucial in the modern era, both in academic and professional pursuits. Outside of academia, I have a passion for traveling and discovering new cultures.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"565557854b18794a17853c879f4e5f6b","permalink":"https://ar-ai.org/author/esra-caki/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/esra-caki/","section":"authors","summary":"I am a PhD student exploring the potential use of cutting-edge technologies such as Artificial Intelligence (AI) and Virtual Reality (VR) in educational contexts. My research primarily focuses on integrating these technologies into training environments to create new and innovative ways to develop soft skills that are crucial in the modern era, both in academic and professional pursuits.","tags":null,"title":"Esra Caki","type":"authors"},{"authors":null,"categories":null,"content":"I am a PhD student specializing in Augmented Reality and interactive content generation, with a focus on human perception and emotion recognition to enhance collaboration and user experience. Originally from the Italian island of Sardinia, I have been living abroad since graduating in 2022. When I’m not immersed in research, I enjoy freediving 🤿.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"8dd629479c15fa9eae9577e028784a78","permalink":"https://ar-ai.org/author/francesco-dettori/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/francesco-dettori/","section":"authors","summary":"I am a PhD student specializing in Augmented Reality and interactive content generation, with a focus on human perception and emotion recognition to enhance collaboration and user experience. Originally from the Italian island of Sardinia, I have been living abroad since graduating in 2022.","tags":null,"title":"Francesco Dettori","type":"authors"},{"authors":null,"categories":null,"content":"Focusing on enhancing user interaction and experience in immersive systems, and exploring collaboration using virtual and augmented reality. Read more on my personal homepage\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"c3aaa49fe88d230f4888d3e4df1e0833","permalink":"https://ar-ai.org/author/huyen-nguyen/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/huyen-nguyen/","section":"authors","summary":"Focusing on enhancing user interaction and experience in immersive systems, and exploring collaboration using virtual and augmented reality. Read more on my personal homepage","tags":null,"title":"Huyen Nguyen","type":"authors"},{"authors":null,"categories":null,"content":"Finishing my last year of my Bachelor’s Degree, I am really excited about Artificial Intelligence and exploring the domain of Computer Vision. Outside my studies and research, I enjoy Powerlifting!\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"9cb6422916216f5bd2a0f7b062e17c73","permalink":"https://ar-ai.org/author/martin-leiva/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/martin-leiva/","section":"authors","summary":"Finishing my last year of my Bachelor’s Degree, I am really excited about Artificial Intelligence and exploring the domain of Computer Vision. Outside my studies and research, I enjoy Powerlifting!","tags":null,"title":"Martín Leiva","type":"authors"},{"authors":null,"categories":null,"content":"I am currently pursuing a Master’s degree in Digital Sciences at Université Paris Cité, France. With a background in both Biotechnology and Data Science, I have a strong interest in interdisciplinary research, particularly in the applications of Artificial Intelligence in Life Sciences and Social Sciences.\nAdditionally, I have over 5 years of experience working in Vietnam’s startup Business, primarily in AI or Education. During my current internship in France, I am contributing to the Standbyme project, which integrates AI and Virtual Reality for conflict management. Beyond my academic and professional pursuits, I enjoy reading and performing music.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"40ebf63d8863c72238e4773485dc4d56","permalink":"https://ar-ai.org/author/pham-hai-nam/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/pham-hai-nam/","section":"authors","summary":"I am currently pursuing a Master’s degree in Digital Sciences at Université Paris Cité, France. With a background in both Biotechnology and Data Science, I have a strong interest in interdisciplinary research, particularly in the applications of Artificial Intelligence in Life Sciences and Social Sciences.","tags":null,"title":"Pham Hai Nam","type":"authors"},{"authors":null,"categories":null,"content":"AI research engineer at CNRS and based at IRISA. I support AI research projects using the Jean-Zay supercomputer and organize training courses.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"c5915bb7c8c46cbe27d7ec26461a74d5","permalink":"https://ar-ai.org/author/thomas-betton/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/thomas-betton/","section":"authors","summary":"AI research engineer at CNRS and based at IRISA. I support AI research projects using the Jean-Zay supercomputer and organize training courses.","tags":null,"title":"Thomas Betton","type":"authors"},{"authors":[],"categories":null,"content":"Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://ar-ai.org/event/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/event/example/","section":"event","summary":"An example event.","tags":[],"title":"Example Event","type":"event"},{"authors":["Hovhannes Margaryan"],"categories":null,"content":"On 28 March 2025, I had the pleasure of participating in ADOS in Paris—a creative technology event—co‑organized by Banodoco and Lightricks at Artifex Lab. Walking into that space, you could feel the excitement: artists, engineers, and technologists converging around the open‑source LTXV model. I’d been following LTXV’s rapid evolution—a text-to-video model that generates video clips from text in real time—so it was thrilling to see the community around it in action.\nFirst Day at ADOS: Talks \u0026amp; Connections In the evening’s lineup, standout presentations ranged from Emma Catnip’s soulful art pieces to Vibeke Bertelsen’s uncanny human forms, and Yvann Barbot’s ComfyUI audio-reactive video demos. My supervisor, Christian Sandor, also delivered an inspiring keynote, and our team showcased a demo exploring the convergence of AR and AI—a project that deeply influenced my own thinking about generative storytelling.\nAmid all this, I found LTXV’s open‑source availability fascinating—not just as technical innovation, but as a platform for collective creativity. Seeing Lightricks being open with their weights and tools seemed like a pivotal moment in democratizing video AI.\nDay Two: Hackathon \u0026amp; Video Editing and Reference-based Style‑Transfer Experiments The very next day I joined the ADOS hackathon, working side by side with others to push LTXV’s limits. Provided computation resources, power, snacks, and steady energy pulses fueled the intense collaborative rhythm of the event. For my project, I focused on one core idea: simultaneous style transfer and editing for text‑to‑video (T2V) using LTXV. Given a style reference image, a video clip, and a text prompt describing the edit, I experimented with three distinct methods to transfer visual style while\nLatent alpha blending: Alpha blending between the inverted style image latent and the inverted latent of the video’s first frame. KV sharing with alpha blending: Repeating the style’s keys and values to match video dimensions (repeat-interleave) and blending them. KV sharing via concatenation: Appending the style’s keys and values to the video’s keys and values for joint processing with full 3D attention. Your browser does not support video. Input Video Reference Style Method 1 Method 2 Method 3 (Layer 5) Method 3 (Layer 27) Text Prompt: A big horse triumphantly at the peak of a towering mountain. Panorama of rugged peaks and valleys. Very futuristic vibe and animated aesthetic. Highlights of purple and golden colors in the scene. The sky is looks like an animated/cartoonish dream of galaxies, nebulae, stars, planets, moons, but the remainder of the scene is mostly realistic.\nFigure 1: Method 1 fails to propagate style information to the generated video. In Method 3, the choice of attention layer for injection critically impacts the outcome: early-layer injection (e.g., layers 5 or 13) suppresses motion and overemphasizes style, whereas later-layer injection (e.g., layer 27) achieves a more balanced integration of style and motion. Style image from Pinterest. Input video from Hugging Face. For the text‑based editing component, I used RF‑Edit. My findings indicate that latent alpha blending is ineffective for style transfer. KV sharing methods can propagate style, but often at the expense of content fidelity or motion consistency. In particular, style injection may introduce unnatural motion not present in the original video. The injection point within the attention layers significantly affects results: early-layer injection (e.g., layers 5 or 13) suppresses motion and overemphasizes style, while later-layer injection (e.g., layer 27) offers a better balance between style and motion.\nReflections \u0026amp; What Comes Next ADOS was an inspiring gathering—not only for witnessing the technical evolution of generative video, but also for experiencing the vibrant culture of open, collaborative experimentation that surrounds it. Huge thanks to the ADOS team—Banodoco, Lightricks, and Artifex Lab—for organizing an inspiring and technically rich weekend. Events like this make open‑source generative video feel alive. I can’t wait to keep building on what started in Paris.\n","date":1756771200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1756771200,"objectID":"68dd1840cc36b3e61a37eae0f0daf30b","permalink":"https://ar-ai.org/post/25-03-28-ados/","publishdate":"2025-09-02T00:00:00Z","relpermalink":"/post/25-03-28-ados/","section":"post","summary":"On 28 March 2025, I had the pleasure of participating in ADOS in Paris—a creative technology event—co‑organized by Banodoco and Lightricks at Artifex Lab. Walking into that space, you could feel the excitement: artists, engineers, and technologists converging around the open‑source LTXV model.","tags":null,"title":"My Experience at ADOS: From Keynotes to Hackathon Experiments","type":"post"},{"authors":["Cristian Rendon","Marie-Anne Burcklen","Richard Legras","Christian Sandor"],"categories":null,"content":"","date":1752105600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1752105600,"objectID":"479a6ea5319202f169158f88375bbe86","permalink":"https://ar-ai.org/publication/av_literature_review/","publishdate":"2025-07-10T00:00:00Z","relpermalink":"/publication/av_literature_review/","section":"publication","summary":"Augmented Reality (AR) has grown from specialised uses to applications for the common public. One of these developments led to Augmented Vision (AV), which enhances vision beyond traditional methods like glasses or contact lenses. This review aims to compare and categorise AV systems according to the paradigms they implement to enhance the users' vision. Additionally, the review examines whether researchers conduct measurements and analysis on the human visual system (HVS) when evaluating their system. Such an overall view will help future researchers position their work on AV. By understanding AV systems' paradigms and approaches, researchers will be well-equipped to identify gaps, explore novel directions, and leverage existing advancements.\nWe searched Scopus, Web of Science, and PubMed databases for publications until February 26, 2025, exploring citations and references for the selected articles to avoid missing out on relevant articles. We then conducted a two-step screening process that involved LLM-assisted screening of the article's abstracts and an in-depth assessment of the article. This review follows the PRISMA statement, reducing bias risk.\nWe selected 113 of 469 articles, as they improved users' visual performance. We defined three main categories: (1) adding light to the incoming light field, (2) modifying the incoming light field, and (3) intersecting approaches. We found three main application areas: (1) task-specific, (2) vision correction, and (3) visual perception enhancement. The most typical application is task-specific. We identified a gap in the literature since just four of the papers we reviewed measured and analysed the accommodation while utilising the device.","tags":[],"title":"Augmented Vision Systems: Paradigms and Applications","type":"publication"},{"authors":["Zofia Samsel"],"categories":null,"content":"Hi, my name is Zofia. Originally from Poland, I am a M2 Master’s student at Université Paris Cité.\nFrom March 2023 to January 2024, I had the opportunity to be part of the ARAI Team as an intern. I joined the lab to work on a project in collaboration with La Chaire Innovation BOPA at Paul Brousse Hospital. I worked under the supervision of Prof. Nguyen Huyen, Prof. Christian Sandor, and Dr Clément Cormi (BOPA). Our focus was on using augmented reality to visualize 3D imaging during open liver surgery.\nDuring my time in the lab, I spent time at the hospital observing surgeries and designing experimental protocols to test how different ways of presenting 3D images impact surgical performance and communication. I also developed a demo app to present 3D reconstructions of the liver using the Canon MREAL HMD, which was later tested by surgeons. We also collaborated with PRIM 3D, a 3D printing lab, to create life-sized silicone liver models, which were later used in the experiment.\nThe project was a challenging yet rewarding experience that gave me valuable insight into how interdisciplinary collaboration between medical and technical expertise can lead to innovative solutions. It showed me how teamwork can help tackle complex tasks and contribute to improving healthcare.\nI was also lucky to attend the Young Researchers in Human-Computer Interaction Meeting in La Rochelle and volunteer at the SUI Symposium on Spatial User Interaction. Both events introduced me to new ideas, cutting-edge research, and inspiring people in the field of HCI.\nBut my internship wasn’t just about research! I met so many interesting people in the lab and had some great experiences outside the lab too. We organized fun outings like a trip to Asterix Park, or ice skating, which helped me feel more connected to the team.\nLooking back, my time with the ARAI Team was a valuable learning experience, both professionally and personally. I’m grateful for the support of my supervisors and colleagues. This experience has shaped my future, and I’m excited to see where it leads next!\n","date":1739836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1739836800,"objectID":"090de10538cc1ca413fccb7f98de8a5a","permalink":"https://ar-ai.org/post/25-02-18-zofia-internship/","publishdate":"2025-02-18T00:00:00Z","relpermalink":"/post/25-02-18-zofia-internship/","section":"post","summary":"Hi, my name is Zofia. Originally from Poland, I am a M2 Master’s student at Université Paris Cité.\nFrom March 2023 to January 2024, I had the opportunity to be part of the ARAI Team as an intern.","tags":null,"title":"Zofia's Internship Report","type":"post"},{"authors":["Mizuki Akiyama"],"categories":null,"content":"Hello, this is Mizuki Akiyama. I’m a master’s student of Ochanomizu University in Japan. I joined team ARAI as an intern for about 2 months, from early October to mid December 2024. Not only did I proceed with my project, but I also met amazing people, so I was able to spend quality time. I will continue to work with team ARAI remotely from Tokyo!\nBefore coming, I had some online meetings with Professor Christian. Since we talked about how we would do the project during the meetings, I started the implementation immediately upon joining. I could focus very well on my project. The project is based on my personal experience as a cheerleader; I want to help cheerleaders to improve their training using XR technologies! Our ultimate goal is to do it with AR, but as a first step, I built a prototype with VR\nFurthermore, we went out for dinner together in Paris, and on another day, I was shown around the city. I had a great time with everyone during the other moments.\nWe had French Japanese food. I tried something called sushi, but it was not real sushi.\nAdditionally, I visited Paris every weekend and I had some trips in Europe. I found it fascinating to experience the different vibes of each country.\nEven though my English is not good, everyone was very welcoming. I’m so glad to experience this internship, and I appreciate their kindness. Please come visit Japan! Thank you very much, ありがとう！\n","date":17388e5,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":17388e5,"objectID":"6136817da3cca6d6ecadf9f199192271","permalink":"https://ar-ai.org/post/25-01-09-mizuki-internship/","publishdate":"2025-02-06T00:00:00Z","relpermalink":"/post/25-01-09-mizuki-internship/","section":"post","summary":"Hello, this is Mizuki Akiyama. I’m a master’s student of Ochanomizu University in Japan. I joined team ARAI as an intern for about 2 months, from early October to mid December 2024.","tags":null,"title":"Mizuki's Internship Report","type":"post"},{"authors":null,"categories":null,"content":"","date":1736258400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1736258400,"objectID":"32be030db0bebe88e8fea5f7a0d8579b","permalink":"https://ar-ai.org/post/25-01-07-offer/","publishdate":"2025-01-07T14:00:00Z","relpermalink":"/post/25-01-07-offer/","section":"post","summary":"We have a postdoc position available, to be filled ASAP. Interested? Click here to read more","tags":["new"],"title":"Postdoc Position Available","type":"post"},{"authors":null,"categories":null,"content":"Canon Japan visited us to present their AR strategy, including their current and future headsets. They also showed several really nice demos. It was fun as you can see in the image gallery below. You can also see Emmanuel Pietriga, leader of team ILDA, in some of the photos.\n","date":1729209600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1729209600,"objectID":"26c5963484a299e6991f328c265a899d","permalink":"https://ar-ai.org/post/24-10-18-canon/","publishdate":"2024-10-18T00:00:00Z","relpermalink":"/post/24-10-18-canon/","section":"post","summary":"Canon Japan visited us to present a talk about their new headesets. They also brought some interesting demos. It was fun!","tags":null,"title":"Visit by Canon Japan","type":"post"},{"authors":null,"categories":null,"content":"At the end of July 2024, we showed a demonstration at the premiere computer graphics conference: ACM SIGGRAPH. We even managed to get into one of their most challenging categories: Real-Time Live!\nClick to read Chris’s detailled experience report.\n","date":1726012800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1726012800,"objectID":"f68ceb1c9579e819dc975be6d3a97754","permalink":"https://ar-ai.org/post/24-09-11-rtl/","publishdate":"2024-09-11T00:00:00Z","relpermalink":"/post/24-09-11-rtl/","section":"post","summary":"At the end of July 2024, we showed a demonstration at the premiere computer graphics conference: ACM SIGGRAPH. We even managed to get into one of their most challenging categories: Real-Time Live!\nClick to read Chris’s detailled experience report.\n","tags":null,"title":"Team ARAI presents at ACM SIGGRAPH 2024 Real-Time Live!","type":"post"},{"authors":null,"categories":null,"content":"","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666569600,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"https://ar-ai.org/contact/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/contact/","section":"","summary":"","tags":null,"title":"Contact","type":"landing"},{"authors":null,"categories":null,"content":"","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666569600,"objectID":"c1d17ff2b20dca0ad6653a3161942b64","permalink":"https://ar-ai.org/people/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/people/","section":"","summary":"","tags":null,"title":"People","type":"landing"},{"authors":null,"categories":null,"content":"","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666569600,"objectID":"b0d61e5cbb7472bf320bf0ef2aaeb977","permalink":"https://ar-ai.org/tour/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/tour/","section":"","summary":"","tags":null,"title":"Tour","type":"landing"},{"authors":null,"categories":null,"content":"We are always looking for excellent candidates (Postdocs, PhD students, interns) to expand our team. To express your interest, please send your application materials to Christian Sandor:\nCV Transcript of Records Link to portfolio (github, personal homepage, etc.) Research Environment The Laboratoire Interdisciplinaire des Sciences du Numérique (LISN) is a multidisciplinary laboratory at France’s leading research university: Université Paris-Saclay. The successful candidate will be expected to join team ARAI within LISN’s HCI department (IaH).\nTeam ARAI was founded in May 2024 to pioneer the application of AI to AR. It is strongly connected to the large French projects CONTINUUM and ENSEMBLE.\nDesired Skills AR/VR HCI/3DUIs Psychology/Neuroscience Computer Graphics Computer Vision Deep Learning We also consider candidates who are outside of this profile, but who can convince us that they can grow into it. Postdocs Summary Starting date: continuously Salary: up to EUR 4291 (gross per month; depending on experience) Introduction Generative Artiﬁcial Intelligence (AI) and Augmented Reality (AR) have made incredible progress over the last few years. We are not far away from a future, in which a user’s view could be continuously modified by their smart glasses. Besides some obvious ethical concerns about such a future, there are also immense opportunities for using this capability to make our lives better. The high-level context of this position is to help us develop fundamental technologies and study their applications and effects on humans.\nA special benefit of this position is that is intended to support outstanding young researchers to prepare an application for a lifetime position at CNRS. These positions are unique, as they provide the probably fastest tracks for talented young researchers to get a tenured position (more than 5 years faster than a comparable track in e.g. the USA). CNRS positions also come with a status as French civil servant, which includes significant benefits (e.g. sabbaticals with a duration of up to 8 years, true lifetime employment, an attractive pension, etc.).\nThe ideal candidate has 2-3 years of postdoc experience.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f55673f390fd8ac84e9d16134712a8de","permalink":"https://ar-ai.org/offers/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/offers/","section":"","summary":"We are always looking for excellent candidates (Postdocs, PhD students, interns) to expand our team. To express your interest, please send your application materials to Christian Sandor:\nCV Transcript of Records Link to portfolio (github, personal homepage, etc.","tags":null,"title":"Job Offers","type":"page"}]